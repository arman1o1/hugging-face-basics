{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ Chapter 6.1: Fine-tuning Pretrained Models on Hugging Face\n",
    "\n",
    "---\n",
    "\n",
    "## üìö What You'll Learn\n",
    "\n",
    "In this notebook, we'll explore **fine-tuning** - a powerful technique that allows you to take a pretrained model and adapt it for your specific use case. By the end of this notebook, you'll understand:\n",
    "\n",
    "1. **What is Fine-tuning?** - Understanding the concept and why it's important\n",
    "2. **Loading & Preparing Datasets** - Working with Hugging Face datasets\n",
    "3. **Tokenization** - Converting text to model-ready format\n",
    "4. **Setting Up Models** - Configuring pretrained models for classification\n",
    "5. **Training with Trainer API** - Using Hugging Face's powerful training utilities\n",
    "6. **Inference** - Using your fine-tuned model for predictions\n",
    "7. **Multiclass Classification** - Extending to more complex scenarios\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Understanding Fine-tuning\n",
    "\n",
    "**Fine-tuning** is like teaching an expert a new specialty. Imagine a doctor who has years of general medical training (pretrained model). Instead of training a new doctor from scratch for cardiology, you take this experienced doctor and give them specialized cardiology training (fine-tuning). They already understand medicine fundamentals, so they learn the specialty faster and with less effort!\n",
    "\n",
    "### Why Fine-tune?\n",
    "\n",
    "| Approach | Training Data Needed | Time Required | Performance |\n",
    "|----------|---------------------|---------------|-------------|\n",
    "| Train from Scratch | Millions of examples | Days/Weeks | Variable |\n",
    "| Fine-tuning | Thousands of examples | Minutes/Hours | High |\n",
    "| Zero-shot (no training) | None | Instant | Moderate |\n",
    "\n",
    "Fine-tuning offers the **sweet spot** between effort and performance!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üõ†Ô∏è Setup & Installation\n",
    "\n",
    "Let's start by installing and importing the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install transformers datasets torch accelerate -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import essential libraries\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Using CUDA GPU: \n",
      "Device selected: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU availability\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"üöÄ Using CUDA GPU: {torch.cuda.get_device_name(0)}\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"üçé Using Apple Silicon MPS\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"üíª Using CPU (training will be slower)\")\n",
    "\n",
    "print(f\"Device selected: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Part 1: Binary Classification - Movie Review Sentiment Analysis\n",
    "\n",
    "For our first fine-tuning exercise, we'll use the **IMDB movie reviews dataset** to classify reviews as positive or negative.\n",
    "\n",
    "### 1.1 Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40b4afeaf4c64684aede8dc00ce61570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c841bd5427c74813b1ebf2e016e9cff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3923c55636c6466aab176b50b8823d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8e608dd9df5425bb692dc74006cbb85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/unsupervised-00000-of-00001.p(‚Ä¶):   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b4276a6a814812b96d5d77471b5636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e433d365ec494f83953a5bb9cd41b7a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ac2dc5a48e4f9fad3f81e57710709d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ IMDB Dataset Structure:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    unsupervised: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Load the IMDB dataset\n",
    "imdb_dataset = load_dataset(\"imdb\")\n",
    "\n",
    "print(\"üì¶ IMDB Dataset Structure:\")\n",
    "print(imdb_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé¨ Sample Movie Review:\n",
      "==================================================\n",
      "Text (first 500 chars): I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attent...\n",
      "\n",
      "Label: 0 (Negative üëé)\n"
     ]
    }
   ],
   "source": [
    "# Let's examine a sample review\n",
    "sample = imdb_dataset['train'][0]\n",
    "\n",
    "print(\"üé¨ Sample Movie Review:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Text (first 500 chars): {sample['text'][:500]}...\")\n",
    "print(f\"\\nLabel: {sample['label']} ({'Positive üëç' if sample['label'] == 1 else 'Negative üëé'})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Creating a Subset for Faster Training\n",
    "\n",
    "The full IMDB dataset has 25,000 training examples. For learning purposes, we'll use a smaller subset to speed up training while still achieving good results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Subset Dataset:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 3000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "})\n",
      "\n",
      "‚úÖ Using 3000 training and 1000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Create a manageable subset for training\n",
    "NUM_TRAIN_SAMPLES = 3000\n",
    "NUM_TEST_SAMPLES = 1000\n",
    "\n",
    "# Shuffle and select subsets\n",
    "train_subset = imdb_dataset['train'].shuffle(seed=42).select(range(NUM_TRAIN_SAMPLES))\n",
    "test_subset = imdb_dataset['test'].shuffle(seed=42).select(range(NUM_TEST_SAMPLES))\n",
    "\n",
    "# Combine into a DatasetDict\n",
    "movie_dataset = DatasetDict({\n",
    "    'train': train_subset,\n",
    "    'test': test_subset\n",
    "})\n",
    "\n",
    "print(f\"üìä Subset Dataset:\")\n",
    "print(movie_dataset)\n",
    "print(f\"\\n‚úÖ Using {NUM_TRAIN_SAMPLES} training and {NUM_TEST_SAMPLES} test samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Label Distribution in Training Set:\n",
      "   Positive reviews: 1489 (49.6%)\n",
      "   Negative reviews: 1511 (50.4%)\n"
     ]
    }
   ],
   "source": [
    "# Let's check the label distribution\n",
    "train_labels = movie_dataset['train']['label']\n",
    "positive_count = sum(train_labels)\n",
    "negative_count = len(train_labels) - positive_count\n",
    "\n",
    "print(\"üìà Label Distribution in Training Set:\")\n",
    "print(f\"   Positive reviews: {positive_count} ({positive_count/len(train_labels)*100:.1f}%)\")\n",
    "print(f\"   Negative reviews: {negative_count} ({negative_count/len(train_labels)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Tokenization - Converting Text to Numbers\n",
    "\n",
    "Models don't understand text directly - they need numbers! **Tokenization** converts our text into tokens (think of them as word pieces) and then into numerical IDs.\n",
    "\n",
    "We'll use **DistilBERT**, a smaller and faster version of BERT that retains 97% of its performance while being 60% faster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c381752266548ebb2690a46d2c64870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c226cc9f2cbe40eba1e9d8379efbfb59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d8fdc025f61461a908039df7c23de2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a356a6e80884dd9a527a3e8552ca6a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded tokenizer for: distilbert-base-uncased\n",
      "   Vocabulary size: 30,522 tokens\n"
     ]
    }
   ],
   "source": [
    "# Define the model checkpoint\n",
    "MODEL_CHECKPOINT = \"distilbert-base-uncased\"\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
    "\n",
    "print(f\"‚úÖ Loaded tokenizer for: {MODEL_CHECKPOINT}\")\n",
    "print(f\"   Vocabulary size: {tokenizer.vocab_size:,} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî§ Tokenization Example:\n",
      "   Original: This movie was absolutely fantastic! I loved every moment.\n",
      "   Tokens: ['this', 'movie', 'was', 'absolutely', 'fantastic', '!', 'i', 'loved', 'every', 'moment', '.']\n",
      "   Token IDs: [101, 2023, 3185, 2001, 7078, 10392, 999, 1045, 3866, 2296, 2617, 1012, 102]\n"
     ]
    }
   ],
   "source": [
    "# Let's see tokenization in action\n",
    "sample_text = \"This movie was absolutely fantastic! I loved every moment.\"\n",
    "\n",
    "# Tokenize the sample\n",
    "tokens = tokenizer.tokenize(sample_text)\n",
    "token_ids = tokenizer.encode(sample_text)\n",
    "\n",
    "print(\"üî§ Tokenization Example:\")\n",
    "print(f\"   Original: {sample_text}\")\n",
    "print(f\"   Tokens: {tokens}\")\n",
    "print(f\"   Token IDs: {token_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Tokenizing dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "991bed9382094714bb409d4d6149942c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e92fb7416a194371b1d87bba55441552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tokenization complete!\n",
      "\n",
      "üìä Tokenized Dataset Structure:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 3000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Define the tokenization function\n",
    "def tokenize_function(examples):\n",
    "    \"\"\"\n",
    "    Tokenizes the text with padding and truncation.\n",
    "    \n",
    "    - padding='max_length': Pads shorter texts to max_length\n",
    "    - truncation=True: Cuts longer texts to max_length\n",
    "    - max_length=256: Maximum sequence length (reduced from 512 for speed)\n",
    "    \"\"\"\n",
    "    return tokenizer(\n",
    "        examples['text'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=256  # Shorter for faster training\n",
    "    )\n",
    "\n",
    "# Apply tokenization to the entire dataset\n",
    "print(\"‚è≥ Tokenizing dataset...\")\n",
    "tokenized_movie_dataset = movie_dataset.map(tokenize_function, batched=True)\n",
    "print(\"‚úÖ Tokenization complete!\")\n",
    "\n",
    "# View the new structure\n",
    "print(\"\\nüìä Tokenized Dataset Structure:\")\n",
    "print(tokenized_movie_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tokenized Example:\n",
      "   Keys: dict_keys(['text', 'label', 'input_ids', 'attention_mask'])\n",
      "   Input IDs length: 256\n",
      "   Attention mask length: 256\n",
      "   Label: 1\n"
     ]
    }
   ],
   "source": [
    "# Examine a tokenized example\n",
    "example = tokenized_movie_dataset['train'][0]\n",
    "\n",
    "print(\"üîç Tokenized Example:\")\n",
    "print(f\"   Keys: {example.keys()}\")\n",
    "print(f\"   Input IDs length: {len(example['input_ids'])}\")\n",
    "print(f\"   Attention mask length: {len(example['attention_mask'])}\")\n",
    "print(f\"   Label: {example['label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Setting Up the Pretrained Model\n",
    "\n",
    "Now we load the pretrained DistilBERT model and configure it for our binary classification task. The `num_labels=2` parameter tells the model we have two classes (positive/negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1847358bc46345348683707003648738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model loaded and moved to cuda\n",
      "   Model type: DistilBertForSequenceClassification\n",
      "   Number of parameters: 66,955,010\n"
     ]
    }
   ],
   "source": [
    "# Load the model for sequence classification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_CHECKPOINT,\n",
    "    num_labels=2  # Binary classification: 0=negative, 1=positive\n",
    ")\n",
    "\n",
    "# Move model to the appropriate device\n",
    "model.to(device)\n",
    "\n",
    "print(f\"‚úÖ Model loaded and moved to {device}\")\n",
    "print(f\"   Model type: {type(model).__name__}\")\n",
    "print(f\"   Number of parameters: {model.num_parameters():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìñ Understanding the Model Architecture\n",
    "\n",
    "When you load `AutoModelForSequenceClassification`, Hugging Face automatically:\n",
    "\n",
    "1. **Loads the pretrained transformer** (DistilBERT) - This contains the general language understanding\n",
    "2. **Adds a classification head** - A linear layer that maps the transformer's output to your number of classes\n",
    "\n",
    "The classification head is randomly initialized and needs to be trained on your data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertForSequenceClassification(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x TransformerBlock(\n",
      "          (attention): DistilBertSdpaAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# View model architecture (optional - generates lengthy output)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Training Configuration\n",
    "\n",
    "The `TrainingArguments` class allows us to configure all aspects of training. Let's set up our training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training arguments configured!\n",
      "   Epochs: 3\n",
      "   Batch size: 16\n",
      "   Learning rate: 2e-05\n"
     ]
    }
   ],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    # Output settings\n",
    "    output_dir=\"./movie_sentiment_model\",  # Where to save the model\n",
    "    \n",
    "    # Training hyperparameters\n",
    "    learning_rate=2e-5,              # Small LR to avoid destroying pretrained weights\n",
    "    num_train_epochs=3,              # Number of complete passes through the dataset\n",
    "    per_device_train_batch_size=16,  # Samples processed per training step\n",
    "    per_device_eval_batch_size=16,   # Samples processed per evaluation step\n",
    "    weight_decay=0.01,               # Regularization to prevent overfitting\n",
    "    \n",
    "    # Evaluation strategy\n",
    "    eval_strategy=\"epoch\",           # Evaluate after each epoch\n",
    "    save_strategy=\"epoch\",           # Save checkpoint after each epoch\n",
    "    load_best_model_at_end=True,     # Load the best model when training ends\n",
    "    \n",
    "    # Logging\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    \n",
    "    # Other settings\n",
    "    fp16=torch.cuda.is_available(),  # Use mixed precision if GPU available\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Training arguments configured!\")\n",
    "print(f\"   Epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"   Batch size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"   Learning rate: {training_args.learning_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìñ Understanding Training Hyperparameters\n",
    "\n",
    "| Parameter | Description | Typical Value |\n",
    "|-----------|-------------|---------------|\n",
    "| `learning_rate` | How much to update weights each step. Lower = slower but more stable | 1e-5 to 5e-5 |\n",
    "| `num_train_epochs` | Complete passes through the training data | 2-5 |\n",
    "| `batch_size` | Samples processed before updating weights | 8-32 |\n",
    "| `weight_decay` | Regularization strength to prevent overfitting | 0.01-0.1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Training the Model\n",
    "\n",
    "Now we create the `Trainer` and start the fine-tuning process!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Trainer initialized!\n",
      "   Training samples: 3000\n",
      "   Evaluation samples: 1000\n"
     ]
    }
   ],
   "source": [
    "# Create the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_movie_dataset['train'],\n",
    "    eval_dataset=tokenized_movie_dataset['test'],\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Trainer initialized!\")\n",
    "print(f\"   Training samples: {len(tokenized_movie_dataset['train'])}\")\n",
    "print(f\"   Evaluation samples: {len(tokenized_movie_dataset['test'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting fine-tuning...\n",
      "   This may take several minutes depending on your hardware.\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [564/564 00:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.328400</td>\n",
       "      <td>0.310028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.226900</td>\n",
       "      <td>0.328088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.150300</td>\n",
       "      <td>0.389217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "‚úÖ Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Start training!\n",
    "print(\"üöÄ Starting fine-tuning...\")\n",
    "print(\"   This may take several minutes depending on your hardware.\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "train_result = trainer.train()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Evaluating the model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Evaluation Results:\n",
      "   Loss: 0.3100\n",
      "   Runtime: 0.39 seconds\n",
      "   Samples/second: 2541.86\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(\"üìä Evaluating the model...\")\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "print(\"\\nüìà Evaluation Results:\")\n",
    "print(f\"   Loss: {eval_results['eval_loss']:.4f}\")\n",
    "print(f\"   Runtime: {eval_results['eval_runtime']:.2f} seconds\")\n",
    "print(f\"   Samples/second: {eval_results['eval_samples_per_second']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Saving the Fine-tuned Model\n",
    "\n",
    "Let's save our model so we can use it later without retraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model saved to: ./movie_sentiment_model/final\n"
     ]
    }
   ],
   "source": [
    "# Save the model and tokenizer\n",
    "MODEL_SAVE_PATH = \"./movie_sentiment_model/final\"\n",
    "\n",
    "model.save_pretrained(MODEL_SAVE_PATH)\n",
    "tokenizer.save_pretrained(MODEL_SAVE_PATH)\n",
    "\n",
    "print(f\"‚úÖ Model saved to: {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 Using the Fine-tuned Model for Inference\n",
    "\n",
    "Now let's test our model on some new movie reviews!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model loaded for inference!\n"
     ]
    }
   ],
   "source": [
    "# Load the fine-tuned model\n",
    "inference_model = AutoModelForSequenceClassification.from_pretrained(MODEL_SAVE_PATH)\n",
    "inference_tokenizer = AutoTokenizer.from_pretrained(MODEL_SAVE_PATH)\n",
    "\n",
    "inference_model.to(device)\n",
    "inference_model.eval()  # Set to evaluation mode\n",
    "\n",
    "print(\"‚úÖ Model loaded for inference!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text):\n",
    "    \"\"\"\n",
    "    Predicts the sentiment of a movie review.\n",
    "    \n",
    "    Args:\n",
    "        text: The movie review text\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary with sentiment and confidence\n",
    "    \"\"\"\n",
    "    # Tokenize the input\n",
    "    inputs = inference_tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=256\n",
    "    )\n",
    "    \n",
    "    # Move inputs to device\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = inference_model(**inputs)\n",
    "        probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        predicted_class = torch.argmax(probabilities, dim=-1).item()\n",
    "        confidence = probabilities[0][predicted_class].item()\n",
    "    \n",
    "    sentiment = \"Positive üëç\" if predicted_class == 1 else \"Negative üëé\"\n",
    "    \n",
    "    return {\n",
    "        \"sentiment\": sentiment,\n",
    "        \"confidence\": confidence,\n",
    "        \"class\": predicted_class\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé¨ Movie Review Sentiment Analysis\n",
      "============================================================\n",
      "\n",
      "Review 1:\n",
      "   This is hands down the best sci-fi movie I've seen in years! \n",
      "    The special effects were mind-blow...\n",
      "   ‚Üí Positive üëç (Confidence: 94.50%)\n",
      "\n",
      "Review 2:\n",
      "   What a waste of two hours. The plot made no sense, the characters \n",
      "    were one-dimensional, and I f...\n",
      "   ‚Üí Negative üëé (Confidence: 95.22%)\n",
      "\n",
      "Review 3:\n",
      "   A decent thriller with some good moments. While the twist at the end \n",
      "    was predictable, the lead ...\n",
      "   ‚Üí Negative üëé (Confidence: 55.35%)\n",
      "\n",
      "Review 4:\n",
      "   Absolutely horrible! The CGI looked like it was from the 90s, \n",
      "    the dialogue was cringeworthy, an...\n",
      "   ‚Üí Negative üëé (Confidence: 95.97%)\n",
      "\n",
      "Review 5:\n",
      "   A masterpiece of modern cinema. Every frame is beautifully crafted, \n",
      "    the score is hauntingly bea...\n",
      "   ‚Üí Positive üëç (Confidence: 95.82%)\n"
     ]
    }
   ],
   "source": [
    "# Test reviews - a mix of positive and negative\n",
    "test_reviews = [\n",
    "    \"\"\"This is hands down the best sci-fi movie I've seen in years! \n",
    "    The special effects were mind-blowing, the storyline kept me engaged \n",
    "    throughout, and the acting was superb. Highly recommend!\"\"\",\n",
    "    \n",
    "    \"\"\"What a waste of two hours. The plot made no sense, the characters \n",
    "    were one-dimensional, and I found myself checking my phone multiple times. \n",
    "    Save your money and skip this one.\"\"\",\n",
    "    \n",
    "    \"\"\"A decent thriller with some good moments. While the twist at the end \n",
    "    was predictable, the lead actor's performance made it worth watching. \n",
    "    Not great, not terrible.\"\"\",\n",
    "    \n",
    "    \"\"\"Absolutely horrible! The CGI looked like it was from the 90s, \n",
    "    the dialogue was cringeworthy, and I actually fell asleep halfway through. \n",
    "    Worst movie of the year.\"\"\",\n",
    "    \n",
    "    \"\"\"A masterpiece of modern cinema. Every frame is beautifully crafted, \n",
    "    the score is hauntingly beautiful, and the performances will stay with \n",
    "    you long after the credits roll. Oscar-worthy!\"\"\"\n",
    "]\n",
    "\n",
    "print(\"üé¨ Movie Review Sentiment Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, review in enumerate(test_reviews, 1):\n",
    "    result = predict_sentiment(review)\n",
    "    print(f\"\\nReview {i}:\")\n",
    "    print(f\"   {review[:100]}...\")\n",
    "    print(f\"   ‚Üí {result['sentiment']} (Confidence: {result['confidence']:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Part 2: Multiclass Classification - Food Review Rating Prediction\n",
    "\n",
    "Now let's tackle a more complex task: predicting review ratings on a 1-5 star scale using the **Yelp Review Full dataset**. We'll filter for food-related reviews to create a focused food rating predictor!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Loading Yelp Review Full dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b61e1bb06e2746eab0d0be72830118d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed28df1d4cd94bd2bd79e9953e9ff959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "yelp_review_full/train-00000-of-00001.pa(‚Ä¶):   0%|          | 0.00/299M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560455f23cb84cc2afebe42e7206cd55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "yelp_review_full/test-00000-of-00001.par(‚Ä¶):   0%|          | 0.00/23.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "800876a151164641a8e0776dc80df7e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/650000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea9e6d270d8466bb0d23e9345370434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['label', 'text'],\n",
      "        num_rows: 650000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['label', 'text'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Load Yelp Review Full dataset for multiclass classification\n",
    "# This dataset has 5 classes (1-5 star ratings)\n",
    "print(\"üì¶ Loading Yelp Review Full dataset...\")\n",
    "\n",
    "yelp_full = load_dataset(\"yelp_review_full\")\n",
    "print(yelp_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Sample Review:\n",
      "   Text: My expectations for McDonalds are t rarely high. But for one to still fail so spectacularly...that takes something special!\\nThe cashier took my friends's order, then promptly ignored me. I had to force myself in front of a cashier who opened his register to wait on the person BEHIND me. I waited ov...\n",
      "   Label: 0\n",
      "\n",
      "   This means: ‚≠ê (1 star - Very Negative)\n"
     ]
    }
   ],
   "source": [
    "# Examine a sample\n",
    "sample = yelp_full['train'][100]\n",
    "\n",
    "print(\"üìù Sample Review:\")\n",
    "print(f\"   Text: {sample['text'][:300]}...\")\n",
    "print(f\"   Label: {sample['label']}\")\n",
    "\n",
    "# Label mapping explanation\n",
    "label_names = {\n",
    "    0: \"‚≠ê (1 star - Very Negative)\",\n",
    "    1: \"‚≠ê‚≠ê (2 stars - Negative)\",\n",
    "    2: \"‚≠ê‚≠ê‚≠ê (3 stars - Neutral)\",\n",
    "    3: \"‚≠ê‚≠ê‚≠ê‚≠ê (4 stars - Positive)\",\n",
    "    4: \"‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5 stars - Very Positive)\"\n",
    "}\n",
    "\n",
    "print(f\"\\n   This means: {label_names[sample['label']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Filtering for food-related reviews...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15144c9583c045069d5fa4b6b574492e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/650000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81dd31a3f5174304ad67eeafa2054c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Found 468163 training and 36037 test reviews about food\n",
      "\n",
      "üìä Final Dataset:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['label', 'text'],\n",
      "        num_rows: 2500\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['label', 'text'],\n",
      "        num_rows: 500\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Create a subset for faster training\n",
    "NUM_TRAIN = 2500\n",
    "NUM_TEST = 500\n",
    "\n",
    "# Filter for food-related reviews (our creative twist!)\n",
    "def is_food_related(example):\n",
    "    text = example['text'].lower()\n",
    "    food_keywords = ['food', 'restaurant', 'dinner', 'lunch', 'breakfast', 'meal', 'dish', 'eat']\n",
    "    return any(keyword in text for keyword in food_keywords)\n",
    "\n",
    "print(\"‚è≥ Filtering for food-related reviews...\")\n",
    "food_train = yelp_full['train'].filter(is_food_related)\n",
    "food_test = yelp_full['test'].filter(is_food_related)\n",
    "\n",
    "print(f\"   Found {len(food_train)} training and {len(food_test)} test reviews about food\")\n",
    "\n",
    "# Select subsets\n",
    "train_subset = food_train.shuffle(seed=42).select(range(min(NUM_TRAIN, len(food_train))))\n",
    "test_subset = food_test.shuffle(seed=42).select(range(min(NUM_TEST, len(food_test))))\n",
    "\n",
    "# Create DatasetDict\n",
    "food_reviews_dataset = DatasetDict({\n",
    "    'train': train_subset,\n",
    "    'test': test_subset\n",
    "})\n",
    "\n",
    "print(f\"\\nüìä Final Dataset:\")\n",
    "print(food_reviews_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Label Distribution:\n",
      "   ‚≠ê (1 star - Very Negative): 392 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   ‚≠ê‚≠ê (2 stars - Negative): 512 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   ‚≠ê‚≠ê‚≠ê (3 stars - Neutral): 536 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   ‚≠ê‚≠ê‚≠ê‚≠ê (4 stars - Positive): 531 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5 stars - Very Positive): 529 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n"
     ]
    }
   ],
   "source": [
    "# Check label distribution\n",
    "from collections import Counter\n",
    "\n",
    "label_counts = Counter(food_reviews_dataset['train']['label'])\n",
    "\n",
    "print(\"üìä Label Distribution:\")\n",
    "for label in sorted(label_counts.keys()):\n",
    "    count = label_counts[label]\n",
    "    bar = \"‚ñà\" * (count // 10)\n",
    "    print(f\"   {label_names[label]}: {count} {bar}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Tokenization for Multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Tokenizing multiclass dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb5cdf5b93d48c3b1fbe8d8fabd7d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e23a2fdc794adfbb7220c3d7bf94fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tokenization complete!\n"
     ]
    }
   ],
   "source": [
    "# Create a fresh tokenizer for multiclass\n",
    "multiclass_tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
    "\n",
    "def tokenize_for_multiclass(examples):\n",
    "    return multiclass_tokenizer(\n",
    "        examples['text'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "print(\"‚è≥ Tokenizing multiclass dataset...\")\n",
    "tokenized_food_dataset = food_reviews_dataset.map(tokenize_for_multiclass, batched=True)\n",
    "print(\"‚úÖ Tokenization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Setting Up the 5-Class Model\n",
    "\n",
    "The key difference here is `num_labels=5` to handle the 5-star rating system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Multiclass model loaded!\n",
      "   Number of labels: 5\n",
      "   Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Load model for 5-class classification\n",
    "multiclass_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_CHECKPOINT,\n",
    "    num_labels=5  # 5 classes: 1-5 stars (mapped to 0-4 internally)\n",
    ")\n",
    "\n",
    "multiclass_model.to(device)\n",
    "\n",
    "print(f\"‚úÖ Multiclass model loaded!\")\n",
    "print(f\"   Number of labels: 5\")\n",
    "print(f\"   Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Multiclass trainer configured!\n"
     ]
    }
   ],
   "source": [
    "# Training arguments for multiclass (similar but with adjusted settings)\n",
    "multiclass_training_args = TrainingArguments(\n",
    "    output_dir=\"./food_rating_model\",\n",
    "    learning_rate=3e-5,  # Slightly higher for more classes\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    logging_steps=25,\n",
    "    fp16=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "# Create trainer\n",
    "multiclass_trainer = Trainer(\n",
    "    model=multiclass_model,\n",
    "    args=multiclass_training_args,\n",
    "    train_dataset=tokenized_food_dataset['train'],\n",
    "    eval_dataset=tokenized_food_dataset['test'],\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Multiclass trainer configured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting multiclass fine-tuning...\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='471' max='471' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [471/471 00:10, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.123500</td>\n",
       "      <td>1.074790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.955500</td>\n",
       "      <td>1.032564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.740500</td>\n",
       "      <td>1.036507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "‚úÖ Multiclass training complete!\n"
     ]
    }
   ],
   "source": [
    "# Train the multiclass model\n",
    "print(\"üöÄ Starting multiclass fine-tuning...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "multiclass_trainer.train()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ Multiclass training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Multiclass Evaluation Results:\n",
      "   Loss: 1.0326\n",
      "   Runtime: 0.20 seconds\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "multiclass_eval = multiclass_trainer.evaluate()\n",
    "\n",
    "print(\"üìà Multiclass Evaluation Results:\")\n",
    "print(f\"   Loss: {multiclass_eval['eval_loss']:.4f}\")\n",
    "print(f\"   Runtime: {multiclass_eval['eval_runtime']:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Multiclass model saved to: ./food_rating_model/final\n"
     ]
    }
   ],
   "source": [
    "# Save the multiclass model\n",
    "MULTICLASS_SAVE_PATH = \"./food_rating_model/final\"\n",
    "\n",
    "multiclass_model.save_pretrained(MULTICLASS_SAVE_PATH)\n",
    "multiclass_tokenizer.save_pretrained(MULTICLASS_SAVE_PATH)\n",
    "\n",
    "print(f\"‚úÖ Multiclass model saved to: {MULTICLASS_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Multiclass Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Multiclass model loaded for inference!\n"
     ]
    }
   ],
   "source": [
    "# Load the multiclass model for inference\n",
    "rating_model = AutoModelForSequenceClassification.from_pretrained(MULTICLASS_SAVE_PATH)\n",
    "rating_tokenizer = AutoTokenizer.from_pretrained(MULTICLASS_SAVE_PATH)\n",
    "\n",
    "rating_model.to(device)\n",
    "rating_model.eval()\n",
    "\n",
    "print(\"‚úÖ Multiclass model loaded for inference!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(text):\n",
    "    \"\"\"\n",
    "    Predicts the star rating (1-5) for a review.\n",
    "    \n",
    "    Args:\n",
    "        text: The review text\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary with predicted rating and confidence\n",
    "    \"\"\"\n",
    "    inputs = rating_tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=256\n",
    "    )\n",
    "    \n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = rating_model(**inputs)\n",
    "        probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        predicted_class = torch.argmax(probabilities, dim=-1).item()\n",
    "        confidence = probabilities[0][predicted_class].item()\n",
    "    \n",
    "    # Convert 0-4 to 1-5 stars\n",
    "    star_rating = predicted_class + 1\n",
    "    stars = \"‚≠ê\" * star_rating\n",
    "    \n",
    "    return {\n",
    "        \"stars\": star_rating,\n",
    "        \"display\": stars,\n",
    "        \"confidence\": confidence,\n",
    "        \"probabilities\": probabilities[0].cpu().numpy()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üçΩÔ∏è Food Review Rating Predictions\n",
      "============================================================\n",
      "\n",
      "Review 1: \"The food was absolutely incredible! Best Italian restaurant ...\"\n",
      "   Predicted Rating: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5 stars)\n",
      "   Confidence: 81.77%\n",
      "\n",
      "Review 2: \"Terrible experience. The food was cold, the waiter was rude,...\"\n",
      "   Predicted Rating: ‚≠ê (1 stars)\n",
      "   Confidence: 83.78%\n",
      "\n",
      "Review 3: \"It was okay. The food was average, nothing special. \n",
      "    Por...\"\n",
      "   Predicted Rating: ‚≠ê‚≠ê (2 stars)\n",
      "   Confidence: 48.08%\n",
      "\n",
      "Review 4: \"Good food but slow service. The burger was tasty but \n",
      "    we...\"\n",
      "   Predicted Rating: ‚≠ê‚≠ê‚≠ê (3 stars)\n",
      "   Confidence: 53.70%\n",
      "\n",
      "Review 5: \"A culinary masterpiece! The chef's tasting menu was an \n",
      "    ...\"\n",
      "   Predicted Rating: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5 stars)\n",
      "   Confidence: 82.86%\n"
     ]
    }
   ],
   "source": [
    "# Test reviews for multiclass prediction\n",
    "food_test_reviews = [\n",
    "    \"\"\"The food was absolutely incredible! Best Italian restaurant in the city. \n",
    "    The pasta was cooked to perfection and the service was impeccable.\"\"\",\n",
    "    \n",
    "    \"\"\"Terrible experience. The food was cold, the waiter was rude, \n",
    "    and we waited over an hour for our order. Never coming back.\"\"\",\n",
    "    \n",
    "    \"\"\"It was okay. The food was average, nothing special. \n",
    "    Portions were decent for the price. Might try again.\"\"\",\n",
    "    \n",
    "    \"\"\"Good food but slow service. The burger was tasty but \n",
    "    we had to wait 40 minutes. The fries were a bit cold.\"\"\",\n",
    "    \n",
    "    \"\"\"A culinary masterpiece! The chef's tasting menu was an \n",
    "    unforgettable journey. Worth every penny. 10/10 would recommend!\"\"\"\n",
    "]\n",
    "\n",
    "print(\"üçΩÔ∏è Food Review Rating Predictions\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, review in enumerate(food_test_reviews, 1):\n",
    "    result = predict_rating(review)\n",
    "    print(f\"\\nReview {i}: \\\"{review[:60]}...\\\"\")\n",
    "    print(f\"   Predicted Rating: {result['display']} ({result['stars']} stars)\")\n",
    "    print(f\"   Confidence: {result['confidence']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Pushing Model to Hugging Face Hub ü§ó\n",
    "\n",
    "You can share your fine-tuned model with the world by pushing it to the Hugging Face Hub. This makes it easy for others to use your model and for you to access it from anywhere!\n",
    "\n",
    "**Prerequisites:**\n",
    "- A Hugging Face account (free at [huggingface.co](https://huggingface.co))\n",
    "- Hugging Face CLI login or access token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b78f4d0ab384b598bf624e59bccc7e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First, login to Hugging Face Hub\n",
    "# Option 1: Using notebook login (interactive)\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n",
    "\n",
    "# Option 2: Using token directly (uncomment if preferred)\n",
    "# from huggingface_hub import login\n",
    "# login(token=\"your_hf_token_here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model from disk\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from huggingface_hub import create_repo, HfApi\n",
    "\n",
    "MULTICLASS_SAVE_PATH = \"./food_rating_model/final\"\n",
    "\n",
    "print(\"üìÇ Loading saved model from disk...\")\n",
    "saved_model = AutoModelForSequenceClassification.from_pretrained(MULTICLASS_SAVE_PATH)\n",
    "saved_tokenizer = AutoTokenizer.from_pretrained(MULTICLASS_SAVE_PATH)\n",
    "print(\"‚úÖ Model loaded!\")\n",
    "\n",
    "# Define your Hugging Face username and model name\n",
    "HF_USERNAME = \"your-username\"  # üëà Replace with your HF username\n",
    "MODEL_NAME = \"your model name\"\n",
    "\n",
    "# Full repository ID\n",
    "repo_id = f\"{HF_USERNAME}/{MODEL_NAME}\"\n",
    "\n",
    "# Create repo if it doesn't exist (optional - push_to_hub does this automatically)\n",
    "# Set private=True if you want a private repository\n",
    "try:\n",
    "    create_repo(repo_id, exist_ok=True, private=False)\n",
    "    print(f\"‚úÖ Repository ready: {repo_id}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ÑπÔ∏è Note: {e}\")\n",
    "\n",
    "print(f\"\\nüöÄ Pushing model to: {repo_id}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Push the model and tokenizer to Hub\n",
    "saved_model.push_to_hub(repo_id)\n",
    "saved_tokenizer.push_to_hub(repo_id)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(f\"‚úÖ Model successfully pushed!\")\n",
    "print(f\"üîó View your model at: https://huggingface.co/{repo_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Alternative: Push using the Trainer (includes training metrics)\n",
    "# # This is useful if you want to include training logs and metrics\n",
    "# # Uncomment to use:\n",
    "\n",
    "# # Define your Hugging Face username and model name\n",
    "# HF_USERNAME = \"your-username\"  # üëà Replace with your HF username\n",
    "# MODEL_NAME = \"your model name\"\n",
    "\n",
    "# # Full repository ID\n",
    "# repo_id = f\"{HF_USERNAME}/{MODEL_NAME}\"\n",
    "\n",
    "# trainer.push_to_hub(repo_id)     # trainer name should be same as you defined\n",
    "# tokenizer.push_to_hub(repo_id)   # tokenizer name should be same as you defined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Using Your Published Model\n",
    "\n",
    "Once pushed, anyone can use your model with just two lines of code:\n",
    "\n",
    "```python\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load your model from the Hub\n",
    "classifier = pipeline(\"text-classification\", model=\"your-username/food-rating-predictor-distilbert\")\n",
    "\n",
    "# Predict ratings!\n",
    "reviews = [\n",
    "    \"The pizza was absolutely delicious!\",\n",
    "    \"Worst restaurant experience ever.\",\n",
    "    \"Food was okay, nothing special.\"\n",
    "]\n",
    "\n",
    "for review in reviews:\n",
    "    result = classifier(review)\n",
    "    print(f\"Review: {review}\")\n",
    "    print(f\"Predicted: {result}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Key Takeaways\n",
    "\n",
    "### What We Learned:\n",
    "\n",
    "1. **Fine-tuning Process**\n",
    "   - Load pretrained model ‚Üí Prepare dataset ‚Üí Tokenize ‚Üí Train ‚Üí Evaluate ‚Üí Save\n",
    "\n",
    "2. **Binary vs Multiclass Classification**\n",
    "   - Binary: `num_labels=2` (positive/negative)\n",
    "   - Multiclass: `num_labels=n` (e.g., 5 for star ratings)\n",
    "\n",
    "3. **Key Classes from Hugging Face**\n",
    "   - `AutoTokenizer`: Handles text-to-token conversion\n",
    "   - `AutoModelForSequenceClassification`: Model with classification head\n",
    "   - `TrainingArguments`: Training configuration\n",
    "   - `Trainer`: Handles the training loop\n",
    "\n",
    "4. **Best Practices**\n",
    "   - Use small learning rates (2e-5 to 5e-5) to preserve pretrained knowledge\n",
    "   - Filter and subset large datasets for manageable training\n",
    "   - Save models after training for reuse\n",
    "   - Use appropriate device (GPU/MPS/CPU) for efficiency\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Try fine-tuning on your own datasets\n",
    "- Experiment with different base models (BERT, RoBERTa, etc.)\n",
    "- Add metrics like accuracy, F1-score to evaluation\n",
    "- Explore hyperparameter tuning for better results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö References & Resources\n",
    "\n",
    "- [Hugging Face Transformers Documentation](https://huggingface.co/docs/transformers)\n",
    "- [Hugging Face Datasets](https://huggingface.co/docs/datasets)\n",
    "- [Fine-tuning Guide](https://huggingface.co/docs/transformers/training)\n",
    "- [DistilBERT Paper](https://arxiv.org/abs/1910.01108)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
